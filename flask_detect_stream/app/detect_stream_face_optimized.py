
import cv2, time, os
import numpy as np
from ultralytics import YOLO
from deepface import DeepFace
from face.recognize_face import recg_face  # å‡è®¾ä½ æœ‰ä¸€ä¸ªäººè„¸è¯†åˆ«æ¨¡å—
from face.recognize_face import save_face  # å‡è®¾ä½ æœ‰ä¸€ä¸ªä¿å­˜äººè„¸å›¾ç‰‡çš„æ¨¡å—
from face.recognize_face import recg_face_nums
from app.waste_detector import is_waste_plate, draw_food_ratio_on_frame 
from app.face_capture import process_face_and_capture  # æ ¹æ®ä½ çš„è·¯å¾„è°ƒæ•´

# æ¨¡å‹åŠ è½½
# yolo = YOLO("models/yolo11n-seg.pt")  # å®ä¾‹åˆ†å‰²æ¨¡å‹


# yolo = YOLO("models/yolov8s-seg.pt") # ä½¿ç”¨YOLOv8s-segæ¨¡å‹ï¼Œç¡®ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®
yolo = YOLO("models/yolov8n-seg.pt") 

# yolo = YOLO("models/yolo11n.pt")  # æ›¿æ¢ä¸ºå®é™…æ¨¡å‹è·¯å¾„
# è®°å½•æ¯ä¸ªäººä¸Šæ¬¡æˆªå›¾æ—¶é—´
last_capture_time = {}

def run_detection_face_food2(video_source=0):
    global last_capture_time
    cap = cv2.VideoCapture(video_source)
    os.makedirs("waste_captures", exist_ok=True)
    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame_count += 1

        # æ§åˆ¶å¤„ç†é¢‘ç‡
        if frame_count % 3 != 0:
            continue


        res = yolo.predict(source=frame, imgsz=640, verbose=False)[0]
        annotated = res.plot()

        process_frame_logic(res, frame, annotated, last_capture_time) 

        # è§†é¢‘æµè¿”å›
        ret2, buf = cv2.imencode(".jpg", annotated)
        if not ret2:
            continue
        frame_bytes = buf.tobytes()
        yield (b"--frame\r\n"
               b"Content-Type: image/jpeg\r\n\r\n" + frame_bytes + b"\r\n")

    cap.release() 

def process_frame_logic(res, frame, annotated, last_capture_time, waste_threshold=0.25):
    """
    ä¼˜åŒ–åä¸šåŠ¡é€»è¾‘ï¼šå…ˆæ£€æµ‹äººè„¸ï¼Œæœ‰äººæ‰åˆ¤æ–­æ˜¯å¦æœ‰æµªè´¹ï¼Œé¿å…ç©ºè€—èµ„æºã€‚
    """
    # ğŸ” Step 1: æå–äººè„¸
    try:
        face_imgs = DeepFace.extract_faces(frame, detector_backend="mtcnn", enforce_detection=False)
    except Exception as e:
        print(f"[ERROR] Face extraction failed: {e}")
        face_imgs = []
 
 
    if not face_imgs:
        print("[DEBUG] æ— äººè„¸ï¼Œè·³è¿‡æœ¬å¸§")
        return last_capture_time  # æ²¡æœ‰äººè„¸ï¼Œè·³è¿‡åç»­è®¡ç®—

    print(f"[DEBUG] Detected Faces: {len(face_imgs)}")

    # ğŸ§  Step 2: åˆ¤æ–­æ˜¯å¦å­˜åœ¨æµªè´¹ï¼ˆå…ˆç¡®ä¿æœ‰åˆ†å‰²ç»“æœï¼‰
    if res.masks is None or res.masks.data is None:
        print("[WARNING] å½“å‰å¸§æ— åˆ†å‰²ç»“æœï¼Œè·³è¿‡æµªè´¹åˆ¤æ–­")
        return last_capture_time

    masks = res.masks.data.cpu().numpy()
    plates = [(b.xyxy.cpu().numpy()[0], cls)
              for b, cls in zip(res.boxes, res.boxes.cls.cpu().numpy()) if cls == 1]

    if not (masks.size > 0 and plates):
        print("[DEBUG] æ— é¤ç›˜æˆ–é£Ÿç‰©ï¼Œè·³è¿‡æµªè´¹åˆ¤æ–­")
        return last_capture_time

    frame_area = frame.shape[0] * frame.shape[1]
    waste_flag, ratio = is_waste_plate(res, frame_area, waste_threshold)

    if not waste_flag:
        print("[DEBUG] æ£€æµ‹åˆ°æœ‰äººï¼Œä½†æ— æµªè´¹è¡Œä¸ºï¼Œè·³è¿‡æˆªå›¾")
        return last_capture_time

    # ğŸ¯ Step 3: æœ‰äºº + æœ‰æµªè´¹ â†’ æ ‡æ³¨ + é™æµæˆªå›¾
    draw_food_ratio_on_frame(annotated, plates[0][0], ratio)
    last_capture_time = process_face_and_capture(face_imgs, annotated, last_capture_time)

    return last_capture_time
